{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17dcbdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import shutil\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d70cf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.23.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.2.0)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9bdaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7eda7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cropped_images_if_2_eyes(imagePath):\n",
    "    img=cv2.imread(imagePath)\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY);\n",
    "    face=face_cascade.detectMultiScale(gray,1.3,5)\n",
    "    for (x,y,w,h) in face:\n",
    "        roi_gray=gray[y:y+h,x:x+h]\n",
    "        roi_color=img[y:y+h,x:x+h]\n",
    "        eyes=eye_cascade.detectMultiScale(roi_gray)\n",
    "        if(len(eyes)>=2):\n",
    "            return roi_color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd471514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8493758",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dirs=[]\n",
    "path_data=\"./dataset/\"\n",
    "path_to_face=\"./dataset/cropped/\"\n",
    "for entry in os.scandir(path_data):\n",
    "    if(entry.is_dir() and entry.path!=\"./dataset/cropped\"):\n",
    "        image_dirs.append(entry.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d0c522e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./dataset/cristiano_ronaldo',\n",
       " './dataset/lionel_messi',\n",
       " './dataset/maria_sharapova',\n",
       " './dataset/roger_federer',\n",
       " './dataset/serena_williams',\n",
       " './dataset/virat_kohli']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bf5de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists(path_to_face)==False):\n",
    "    os.mkdir(path_to_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "063d4b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image_dir=[]\n",
    "celebrity_file_names={}\n",
    "for imgD in image_dirs:\n",
    "    #going throigh each celeb web mined pics\n",
    "    count=0\n",
    "    #getting name\n",
    "    celebrity_name=imgD.split('/')[-1]\n",
    "    celebrity_file_names[celebrity_name]=[]\n",
    "    temp_path=path_to_face+celebrity_name\n",
    "    if not os.path.exists(temp_path):\n",
    "        #making folder to stored cleaned images\n",
    "        os.mkdir(temp_path)\n",
    "        ## to cropped_image_dir\n",
    "        cropped_image_dir.append(temp_path) ##change location in future if needed outside if block\n",
    "    for entry in os.scandir(imgD):\n",
    "        #iterating through all images in original\n",
    "        roi_color=get_cropped_images_if_2_eyes(entry.path)\n",
    "        if(roi_color is not None):\n",
    "            #if image meets cleaning parameter store to folder\n",
    "            cropped_file_name=celebrity_name+str(count)+\".png\"\n",
    "            cropped_file_path=temp_path+\"/\"+cropped_file_name\n",
    "            cv2.imwrite(cropped_file_path,roi_color)\n",
    "            celebrity_file_names[celebrity_name].append(cropped_file_path)\n",
    "            count=count+1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13404ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "celebrity_file_names.keys()\n",
    "celeb_map={}\n",
    "count=0;\n",
    "for i in celebrity_file_names.keys():\n",
    "    celeb_map[i]=count;\n",
    "    count=count+1;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "412069d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "import cv2    \n",
    "## doing haar transform to do feature extraction\n",
    "\n",
    "def w2d(img, mode='haar', level=1):\n",
    "    imArray = img\n",
    "    #Datatype conversions\n",
    "    #convert to grayscale\n",
    "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
    "    #convert to float\n",
    "    imArray =  np.float32(imArray)   \n",
    "    imArray /= 255;\n",
    "    # compute coefficients \n",
    "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
    "\n",
    "    #Process Coefficients\n",
    "    coeffs_H=list(coeffs)  \n",
    "    coeffs_H[0] *= 0;  \n",
    "\n",
    "    # reconstruction\n",
    "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
    "    imArray_H *= 255;\n",
    "    imArray_H =  np.uint8(imArray_H)\n",
    "\n",
    "    return imArray_H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7dd565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "#creating dataset by appending images vertical with har transofromed images with \n",
    "for celebrity_name, training_files in celebrity_file_names.items():\n",
    "    for training_image in training_files:\n",
    "        img = cv2.imread(training_image)\n",
    "        if(img is None):\n",
    "            continue\n",
    "        scalled_raw_img = cv2.resize(img, (32, 32))\n",
    "        img_har = w2d(img,'db1',5)\n",
    "        scalled_img_har = cv2.resize(img_har, (32, 32))\n",
    "        combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_img_har.reshape(32*32,1)))\n",
    "        X.append(combined_img)\n",
    "        y.append(celeb_map[celebrity_name])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56436d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 42.,  26.,  20., ...,   2.,   6.,   1.],\n",
       "       [100., 129., 140., ..., 237., 234., 232.],\n",
       "       [ 90.,  66.,  67., ...,  36., 247.,  23.],\n",
       "       ...,\n",
       "       [211., 222., 226., ..., 213., 178.,  17.],\n",
       "       [252., 252., 252., ..., 101., 102.,   3.],\n",
       "       [ 25.,  25.,  27., ...,  75.,  41.,  51.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flattening course\n",
    "X = np.array(X).reshape(len(X),4096).astype(float)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba702068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16db3cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(X,y ,random_state=104,test_size=0.25,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24b19615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.82      0.86        11\n",
      "           2       0.91      0.83      0.87        12\n",
      "           3       1.00      0.71      0.83         7\n",
      "           4       0.71      0.62      0.67         8\n",
      "           5       0.67      1.00      0.80        10\n",
      "\n",
      "    accuracy                           0.81        48\n",
      "   macro avg       0.84      0.80      0.81        48\n",
      "weighted avg       0.84      0.81      0.81        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe=Pipeline([('Scale',StandardScaler()),(\"svc\",SVC(kernel=\"rbf\",C=100, probability=True)) ])\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)\n",
    "print(classification_report(y_test, pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd66dd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_svm_piped_model.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipe,\"saved_svm_piped_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20440134",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"celeb_mapping.json\",\"w\") as f:\n",
    "    f.write(json.dumps(celeb_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c38f6b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gg={\n",
    "    \"lionel_messi\": [\"https://twitter.com/imessi\",\"https://www.instagram.com/leomessi/\"],\n",
    "    \"maria_sharapova\": [\"https://twitter.com/MariaSharapova\",\"https://www.instagram.com/mariasharapova/?hl=en\"],\n",
    "    \"roger_federer\": [\"https://twitter.com/rogerfederer\",\"https://www.instagram.com/rogerfederer/\"],\n",
    "    \"serena_williams\": [\"https://twitter.com/serenawilliams\",\"https://www.instagram.com/stories/highlights/17916329126375618/\"],\n",
    "    \"virat_kohli\":[\"https://twitter.com/imVkohli\",\"https://www.instagram.com/virat.kohli/?hl=en\"],\n",
    "    \"Cristiano_Ronaldo\":[\"https://twitter.com/Cristiano\",\"https://www.instagram.com/cristiano/?hl=en\"],\n",
    "    \"Neymar\":[\"https://twitter.com/neymarjr\",\"https://www.instagram.com/neymarjr/?hl=en\"]\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "with open(\"D:\\\\Vishesh\\\\Desktop\\\\study\\\\WEB MINING\\\\project\\\\server\\\\artefacts\\\\celeb_handles.json\",\"w\") as f:\n",
    "    f.write(json.dumps(gg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620b898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa678d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
